{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VNe55yFOqNLfmNWI5TnoK_ByiY_1m_Vq",
      "authorship_tag": "ABX9TyPdhXBaQ3XcGYF2UAfpBy3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmlDC/Truth-Thesis22-23/blob/Scraping-trial/ScrapingNews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTwWZbPg1TVG"
      },
      "outputs": [],
      "source": [
        "import urllib.request,sys,time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"NEWS.csv\"\n",
        "f=open(filename,\"w\", encoding = 'utf-8')\n",
        "headers=\"Statement,Link,Date, Source, Label\\n\"\n",
        "f.write(headers)\n",
        "f.close()\n",
        "  "
      ],
      "metadata": {
        "id": "qqstaujv_h2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pagesToGet= 1\n",
        "upperframe=[]  \n",
        "for page in range(1,pagesToGet+1):\n",
        "    print('processing page :', page)\n",
        "    url = 'https://www.politifact.com/factchecks/list/?page='+str(page)\n",
        "    print(url)\n",
        "    \n",
        "    #an exception might be thrown, so the code should be in a try-except block\n",
        "    try:\n",
        "        #use the browser to get the url. This is suspicious command that might blow up.\n",
        "        page=requests.get(url)                             # this might throw an exception if something goes wrong.\n",
        "    \n",
        "    except Exception as e:                                   # this describes what to do if an exception is thrown\n",
        "        error_type, error_obj, error_info = sys.exc_info()      # get the exception information\n",
        "        print ('ERROR FOR LINK:',url)                          #print the link that cause the problem\n",
        "        print (error_type, 'Line:', error_info.tb_lineno)     #print error info and line that threw the exception\n",
        "        continue                                              #ignore this page. Abandon this and go back.\n",
        "\n",
        "    time.sleep(2)   \n",
        "    soup=BeautifulSoup(page.text,'html.parser')\n",
        "    frame=[]\n",
        "    links=soup.find_all('li',attrs={'class':'o-listicle__item'})\n",
        "    print(len(links))\n",
        "\n",
        "    filename=\"NEWS.csv\"\n",
        "    f=open(filename,\"w\", encoding = 'utf-8')\n",
        "    headers=\"Statement,Link,Date, Source, Label\\n\"\n",
        "    f.write(headers)\n",
        "    \n",
        "    for j in links:\n",
        "        Statement = j.find(\"div\",attrs={'class':'m-statement__quote'}).text.strip()\n",
        "        Link = \"https://www.politifact.com\"\n",
        "        Link += j.find(\"div\",attrs={'class':'m-statement__quote'}).find('a')['href'].strip()\n",
        "        Date = j.find('div',attrs={'class':'m-statement__body'}).find('footer').text[-14:-1].strip()\n",
        "        Source = j.find('div', attrs={'class':'m-statement__meta'}).find('a').text.strip()\n",
        "        Label = j.find('div', attrs ={'class':'m-statement__content'}).find('img',attrs={'class':'c-image__original'}).get('alt').strip()\n",
        "        frame.append((Statement,Link,Date,Source,Label))\n",
        "        f.write(Statement.replace(\",\",\"^\")+\",\"+Link+\",\"+Date.replace(\",\",\"^\")+\",\"+Source.replace(\",\",\"^\")+\",\"+Label.replace(\",\",\"^\")+\"\\n\")\n",
        "    upperframe.extend(frame)\n",
        "f.close()\n",
        "data=pd.DataFrame(upperframe, columns=['Statement','Link','Date','Source','Label'])\n",
        "data.head()"
      ],
      "metadata": {
        "id": "BdgXD6mX2uhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_Smg4pq2v17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}